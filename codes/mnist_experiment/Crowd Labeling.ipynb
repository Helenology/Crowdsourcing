{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1fb778e-ed9f-4961-9ae4-41790aa909b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic (built-in) Python packages\n",
    "import numpy as np\n",
    "from numpy.linalg import norm\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from copy import copy\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# advanced (built-in) Python packages\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy.optimize import minimize\n",
    "from scipy import stats\n",
    "from scipy.stats import norm\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "\n",
    "# my implemented Python functions and classes\n",
    "from utils import *\n",
    "\n",
    "# Deep Learning Library\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "from keras.models import Model\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "from tensorflow.keras.applications.efficientnet import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9aabe350-9410-4fd9-859d-a263026563c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 9\n",
    "EPOCHS = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "967b18d4-5ce3-44f5-a7b9-efcd4f265c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 3) (10000, 28, 28, 3)\n",
      "(60000, 10) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import mnist\n",
    "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
    "\n",
    "# change Xi from (28 x 28) into (28 x 28 x 3)\n",
    "tmp = np.ones(train_X.shape + (3,))\n",
    "tmp *= train_X.reshape(train_X.shape + (1,))\n",
    "train_X = tmp\n",
    "tmp = np.ones(test_X.shape + (3,))\n",
    "tmp *= test_X.reshape(test_X.shape + (1,))\n",
    "test_X = tmp\n",
    "\n",
    "# onehot Yi\n",
    "train_y_onehot = tf.keras.utils.to_categorical(train_y, K + 1)\n",
    "test_y_onehot = tf.keras.utils.to_categorical(test_y, K + 1)\n",
    "print(train_X.shape, test_X.shape)\n",
    "print(train_y_onehot.shape, test_y_onehot.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7155591e-3d6f-4afb-8787-865caf7c9336",
   "metadata": {},
   "source": [
    "# Crowd Labeling \n",
    "\n",
    "- Use train crowd annotators (DLs) on the Testing Set and crowd-label the Training Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9c26c78-0962-4e78-8082-0eda28ba5de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = f\"/mnt/Crowdsourcing/codes/mnist_experiment/crowd models/\"\n",
    "inputs = tf.keras.layers.Input(shape=(28, 28, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65d753a6-eaa7-4c30-8c04-fac83e89f731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9000, 28, 28, 3) (1000, 28, 28, 3) (9000, 10) (1000, 10)\n"
     ]
    }
   ],
   "source": [
    "X0, X1, Y0, Y1 = train_test_split(test_X, test_y_onehot, test_size=0.1, random_state=0)\n",
    "print(X0.shape, X1.shape, Y0.shape, Y1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a06af2e-0efc-4761-845c-ceb48759727c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Since input image size is (28 x 28), first upsample the image by factor of (8x8) to transform it to (224 x 224)\n",
    "Connect the feature extraction and \"classifier\" layers to build the model.\n",
    "'''\n",
    "def final_model(inputs, feature_extractor_model, K):\n",
    "    # Feature Extractor\n",
    "    inputs = preprocess_input(inputs)\n",
    "    resize = tf.keras.layers.UpSampling2D(size=(8, 8))(inputs)\n",
    "    model_feature = feature_extractor_model(resize)\n",
    "    # Classification\n",
    "    '''\n",
    "    Defines final dense layers and subsequent softmax layer for classification.\n",
    "    '''\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(model_feature)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    x = tf.keras.layers.Dense(256, activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.Dense(K + 1, activation=\"softmax\")(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0430661b-f422-441f-ac2f-8469586579c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crowd_label(model, X):\n",
    "    Y_prob = model.predict(X)\n",
    "    Y_hat = np.argmax(Y_prob, axis=1)\n",
    "    return Y_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bc7119-b31f-48c5-a9d8-36ef5d324b8c",
   "metadata": {},
   "source": [
    "## Model 1: MobileNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2aaee1b-8147-4ac7-bd4f-cd19219fe967",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MobileNet\"\n",
    "model_path = base_path + f\"{model_name}.keras\"\n",
    "Yhat_path = f\"./crowd labels/{model_name}_y.npy\"\n",
    "callbacks_list = [ ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                   EarlyStopping(monitor='val_accuracy', patience=10, verbose=2, mode='auto'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e18d0a50-8044-4d00-97b0-580354b38335",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-28 12:53:40.280947: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-28 12:53:41.706313: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:1d:00.0, compute capability: 6.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 4s 0us/step\n",
      "17235968/17225924 [==============================] - 4s 0us/step\n",
      "Model: \"mobilenet_1.00_224\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " conv1 (Conv2D)              (None, 112, 112, 32)      864       \n",
      "                                                                 \n",
      " conv1_bn (BatchNormalizatio  (None, 112, 112, 32)     128       \n",
      " n)                                                              \n",
      "                                                                 \n",
      " conv1_relu (ReLU)           (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_dw_1 (DepthwiseConv2D)  (None, 112, 112, 32)     288       \n",
      "                                                                 \n",
      " conv_dw_1_bn (BatchNormaliz  (None, 112, 112, 32)     128       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_1_relu (ReLU)       (None, 112, 112, 32)      0         \n",
      "                                                                 \n",
      " conv_pw_1 (Conv2D)          (None, 112, 112, 64)      2048      \n",
      "                                                                 \n",
      " conv_pw_1_bn (BatchNormaliz  (None, 112, 112, 64)     256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_1_relu (ReLU)       (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " conv_pad_2 (ZeroPadding2D)  (None, 113, 113, 64)      0         \n",
      "                                                                 \n",
      " conv_dw_2 (DepthwiseConv2D)  (None, 56, 56, 64)       576       \n",
      "                                                                 \n",
      " conv_dw_2_bn (BatchNormaliz  (None, 56, 56, 64)       256       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_2_relu (ReLU)       (None, 56, 56, 64)        0         \n",
      "                                                                 \n",
      " conv_pw_2 (Conv2D)          (None, 56, 56, 128)       8192      \n",
      "                                                                 \n",
      " conv_pw_2_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_2_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_3 (DepthwiseConv2D)  (None, 56, 56, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_3 (Conv2D)          (None, 56, 56, 128)       16384     \n",
      "                                                                 \n",
      " conv_pw_3_bn (BatchNormaliz  (None, 56, 56, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_3_relu (ReLU)       (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " conv_pad_4 (ZeroPadding2D)  (None, 57, 57, 128)       0         \n",
      "                                                                 \n",
      " conv_dw_4 (DepthwiseConv2D)  (None, 28, 28, 128)      1152      \n",
      "                                                                 \n",
      " conv_dw_4_bn (BatchNormaliz  (None, 28, 28, 128)      512       \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_4_relu (ReLU)       (None, 28, 28, 128)       0         \n",
      "                                                                 \n",
      " conv_pw_4 (Conv2D)          (None, 28, 28, 256)       32768     \n",
      "                                                                 \n",
      " conv_pw_4_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_4_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_5 (DepthwiseConv2D)  (None, 28, 28, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_5 (Conv2D)          (None, 28, 28, 256)       65536     \n",
      "                                                                 \n",
      " conv_pw_5_bn (BatchNormaliz  (None, 28, 28, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_5_relu (ReLU)       (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " conv_pad_6 (ZeroPadding2D)  (None, 29, 29, 256)       0         \n",
      "                                                                 \n",
      " conv_dw_6 (DepthwiseConv2D)  (None, 14, 14, 256)      2304      \n",
      "                                                                 \n",
      " conv_dw_6_bn (BatchNormaliz  (None, 14, 14, 256)      1024      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_6_relu (ReLU)       (None, 14, 14, 256)       0         \n",
      "                                                                 \n",
      " conv_pw_6 (Conv2D)          (None, 14, 14, 512)       131072    \n",
      "                                                                 \n",
      " conv_pw_6_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_6_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_7 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_7 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_7_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_7_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_8 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_8 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_8_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_8_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_9 (DepthwiseConv2D)  (None, 14, 14, 512)      4608      \n",
      "                                                                 \n",
      " conv_dw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_dw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_9 (Conv2D)          (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_9_bn (BatchNormaliz  (None, 14, 14, 512)      2048      \n",
      " ation)                                                          \n",
      "                                                                 \n",
      " conv_pw_9_relu (ReLU)       (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_10 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_10 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_10_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_10_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_dw_11 (DepthwiseConv2D  (None, 14, 14, 512)      4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pw_11 (Conv2D)         (None, 14, 14, 512)       262144    \n",
      "                                                                 \n",
      " conv_pw_11_bn (BatchNormali  (None, 14, 14, 512)      2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_11_relu (ReLU)      (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " conv_pad_12 (ZeroPadding2D)  (None, 15, 15, 512)      0         \n",
      "                                                                 \n",
      " conv_dw_12 (DepthwiseConv2D  (None, 7, 7, 512)        4608      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_12_bn (BatchNormali  (None, 7, 7, 512)        2048      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_12_relu (ReLU)      (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " conv_pw_12 (Conv2D)         (None, 7, 7, 1024)        524288    \n",
      "                                                                 \n",
      " conv_pw_12_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_12_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_dw_13 (DepthwiseConv2D  (None, 7, 7, 1024)       9216      \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv_dw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_dw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      " conv_pw_13 (Conv2D)         (None, 7, 7, 1024)        1048576   \n",
      "                                                                 \n",
      " conv_pw_13_bn (BatchNormali  (None, 7, 7, 1024)       4096      \n",
      " zation)                                                         \n",
      "                                                                 \n",
      " conv_pw_13_relu (ReLU)      (None, 7, 7, 1024)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "feature_extractor = keras.applications.MobileNet(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
    "feature_extractor.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decf0e31-9671-41f1-a1db-2380ef26c115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 1: MobileNet\n",
    "feature_extractor = keras.applications.MobileNet(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
    "output = final_model(inputs, feature_extractor, K) \n",
    "model = tf.keras.Model(inputs=inputs, outputs=output, name=model_name)\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c7e7f5c-10b0-444a-985e-abf70f7eba77",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history = model.fit(X0, Y0, validation_data = (X1, Y1), epochs=EPOCHS, batch_size=64, callbacks=callbacks_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "464996cf-f6cb-4f5c-aa6a-065b33b67d94",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-29 02:15:20.026037: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-29 02:15:21.000357: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:1d:00.0, compute capability: 6.0\n",
      "2024-09-29 02:15:25.726687: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict ACC: 0.9894\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(model_path)\n",
    "Yhat = crowd_label(best_model, train_X)\n",
    "print(f\"Predict ACC: {(Yhat == train_y).sum() / len(Yhat)}\")\n",
    "np.save(Yhat_path, Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4f2ea666-025e-4664-845b-006d85a411f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 256)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_extractor = Model(inputs=best_model.input, outputs=best_model.get_layer('dense').output)\n",
    "X = X_extractor.predict(train_X)\n",
    "np.save(\"./feat_X.npy\", X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785158d0-587d-4f13-bdbf-0b53eb308bc9",
   "metadata": {},
   "source": [
    "# Model 2: MobileNet-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "febba89f-4081-4b28-8851-56d6fc905055",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"MobileNet-1\"\n",
    "model_path = base_path + f\"{model_name}.keras\"\n",
    "Yhat_path = f\"./crowd labels/{model_name}_y.npy\"\n",
    "callbacks_list = [ ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                   EarlyStopping(monitor='val_accuracy', patience=10, verbose=2, mode='auto'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16796c5a-7126-4e9f-8fcc-ae5d4b1e9c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 2: MobileNet-1\n",
    "feature_extractor = keras.applications.MobileNet(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "output = final_model(inputs, feature_extractor, K) \n",
    "model = tf.keras.Model(inputs=inputs, outputs=output, name=model_name)\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "61e1be62-85bc-4c20-a7c2-4571a9c20aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 03:00:19.617628: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 0.1543 - accuracy: 0.9506\n",
      "Epoch 1: val_accuracy improved from -inf to 0.96800, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/MobileNet-1.keras\n",
      "141/141 [==============================] - 43s 266ms/step - loss: 0.1543 - accuracy: 0.9506 - val_loss: 0.1255 - val_accuracy: 0.9680\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X0, Y0, validation_data = (X1, Y1), epochs=1, batch_size=64, callbacks=callbacks_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c7390a8-27ab-486d-b894-36acb9e2a19d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict ACC: 0.9520833333333333\n"
     ]
    }
   ],
   "source": [
    "Yhat = crowd_label(model, train_X)\n",
    "print(f\"Predict ACC: {(Yhat == train_y).sum() / len(Yhat)}\")\n",
    "np.save(Yhat_path, Yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949130fd-457d-4cbd-93b7-48a64a884aa4",
   "metadata": {},
   "source": [
    "## Model 3: EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb3deaa7-1015-4366-b66c-9ef7aa1177b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EfficientNet\"\n",
    "model_path = base_path + f\"{model_name}.keras\"\n",
    "Yhat_path = f\"./crowd labels/{model_name}_y.npy\"\n",
    "callbacks_list = [ ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                   EarlyStopping(monitor='val_accuracy', patience=10, verbose=2, mode='auto'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efc35bba-1ba9-4d4b-9b36-ae2ec9b3f95d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 3: EfficientNet\n",
    "feature_extractor = keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "output = final_model(inputs, feature_extractor, K) \n",
    "model = tf.keras.Model(inputs=inputs, outputs=output, name=model_name)\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "83b09bc2-bf93-4dff-9a66-a185aaa80fa1",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1985 - accuracy: 0.9402\n",
      "Epoch 1: val_accuracy improved from -inf to 0.96000, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/EfficientNet.keras\n",
      "141/141 [==============================] - 68s 415ms/step - loss: 0.1985 - accuracy: 0.9402 - val_loss: 0.1510 - val_accuracy: 0.9600\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0469 - accuracy: 0.9849\n",
      "Epoch 2: val_accuracy improved from 0.96000 to 0.96400, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/EfficientNet.keras\n",
      "141/141 [==============================] - 56s 396ms/step - loss: 0.0469 - accuracy: 0.9849 - val_loss: 0.1538 - val_accuracy: 0.9640\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0412 - accuracy: 0.9884\n",
      "Epoch 3: val_accuracy improved from 0.96400 to 0.98800, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/EfficientNet.keras\n",
      "141/141 [==============================] - 55s 392ms/step - loss: 0.0412 - accuracy: 0.9884 - val_loss: 0.0369 - val_accuracy: 0.9880\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0303 - accuracy: 0.9904\n",
      "Epoch 4: val_accuracy did not improve from 0.98800\n",
      "141/141 [==============================] - 53s 379ms/step - loss: 0.0303 - accuracy: 0.9904 - val_loss: 0.1680 - val_accuracy: 0.9610\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0320 - accuracy: 0.9906\n",
      "Epoch 5: val_accuracy improved from 0.98800 to 0.99000, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/EfficientNet.keras\n",
      "141/141 [==============================] - 56s 397ms/step - loss: 0.0320 - accuracy: 0.9906 - val_loss: 0.0378 - val_accuracy: 0.9900\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0293 - accuracy: 0.9916\n",
      "Epoch 6: val_accuracy did not improve from 0.99000\n",
      "141/141 [==============================] - 53s 379ms/step - loss: 0.0293 - accuracy: 0.9916 - val_loss: 0.0571 - val_accuracy: 0.9850\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0137 - accuracy: 0.9957\n",
      "Epoch 7: val_accuracy improved from 0.99000 to 0.99100, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/EfficientNet.keras\n",
      "141/141 [==============================] - 55s 392ms/step - loss: 0.0137 - accuracy: 0.9957 - val_loss: 0.0279 - val_accuracy: 0.9910\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0126 - accuracy: 0.9961\n",
      "Epoch 8: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 54s 380ms/step - loss: 0.0126 - accuracy: 0.9961 - val_loss: 0.0309 - val_accuracy: 0.9880\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9939\n",
      "Epoch 9: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 54s 384ms/step - loss: 0.0187 - accuracy: 0.9939 - val_loss: 0.0345 - val_accuracy: 0.9900\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0119 - accuracy: 0.9959\n",
      "Epoch 10: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 54s 381ms/step - loss: 0.0119 - accuracy: 0.9959 - val_loss: 0.0597 - val_accuracy: 0.9840\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9933\n",
      "Epoch 11: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 53s 379ms/step - loss: 0.0199 - accuracy: 0.9933 - val_loss: 0.0565 - val_accuracy: 0.9830\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9948\n",
      "Epoch 12: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 54s 384ms/step - loss: 0.0175 - accuracy: 0.9948 - val_loss: 0.0516 - val_accuracy: 0.9880\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0138 - accuracy: 0.9964\n",
      "Epoch 13: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 54s 383ms/step - loss: 0.0138 - accuracy: 0.9964 - val_loss: 0.0555 - val_accuracy: 0.9810\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0098 - accuracy: 0.9976\n",
      "Epoch 14: val_accuracy improved from 0.99100 to 0.99200, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/EfficientNet.keras\n",
      "141/141 [==============================] - 55s 390ms/step - loss: 0.0098 - accuracy: 0.9976 - val_loss: 0.0156 - val_accuracy: 0.9920\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0063 - accuracy: 0.9982\n",
      "Epoch 15: val_accuracy did not improve from 0.99200\n",
      "141/141 [==============================] - 54s 381ms/step - loss: 0.0063 - accuracy: 0.9982 - val_loss: 0.0511 - val_accuracy: 0.9880\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0076 - accuracy: 0.9980\n",
      "Epoch 16: val_accuracy did not improve from 0.99200\n",
      "141/141 [==============================] - 54s 381ms/step - loss: 0.0076 - accuracy: 0.9980 - val_loss: 0.0306 - val_accuracy: 0.9920\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0141 - accuracy: 0.9950\n",
      "Epoch 17: val_accuracy did not improve from 0.99200\n",
      "141/141 [==============================] - 53s 378ms/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 0.0824 - val_accuracy: 0.9790\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0270 - accuracy: 0.9931\n",
      "Epoch 18: val_accuracy did not improve from 0.99200\n",
      "141/141 [==============================] - 53s 378ms/step - loss: 0.0270 - accuracy: 0.9931 - val_loss: 0.0260 - val_accuracy: 0.9920\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0093 - accuracy: 0.9969\n",
      "Epoch 19: val_accuracy improved from 0.99200 to 0.99300, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/EfficientNet.keras\n",
      "141/141 [==============================] - 55s 394ms/step - loss: 0.0093 - accuracy: 0.9969 - val_loss: 0.0250 - val_accuracy: 0.9930\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0245 - accuracy: 0.9934\n",
      "Epoch 20: val_accuracy improved from 0.99300 to 0.99500, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/EfficientNet.keras\n",
      "141/141 [==============================] - 56s 395ms/step - loss: 0.0245 - accuracy: 0.9934 - val_loss: 0.0191 - val_accuracy: 0.9950\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0053 - accuracy: 0.9982\n",
      "Epoch 21: val_accuracy did not improve from 0.99500\n",
      "141/141 [==============================] - 53s 378ms/step - loss: 0.0053 - accuracy: 0.9982 - val_loss: 0.0285 - val_accuracy: 0.9930\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0132 - accuracy: 0.9960\n",
      "Epoch 22: val_accuracy did not improve from 0.99500\n",
      "141/141 [==============================] - 53s 378ms/step - loss: 0.0132 - accuracy: 0.9960 - val_loss: 0.0410 - val_accuracy: 0.9880\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0079 - accuracy: 0.9977\n",
      "Epoch 23: val_accuracy did not improve from 0.99500\n",
      "141/141 [==============================] - 53s 378ms/step - loss: 0.0079 - accuracy: 0.9977 - val_loss: 0.0626 - val_accuracy: 0.9840\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9981\n",
      "Epoch 24: val_accuracy did not improve from 0.99500\n",
      "141/141 [==============================] - 54s 380ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.0186 - val_accuracy: 0.9950\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0026 - accuracy: 0.9991\n",
      "Epoch 25: val_accuracy did not improve from 0.99500\n",
      "141/141 [==============================] - 53s 377ms/step - loss: 0.0026 - accuracy: 0.9991 - val_loss: 0.0239 - val_accuracy: 0.9930\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.4879e-04 - accuracy: 1.0000\n",
      "Epoch 26: val_accuracy did not improve from 0.99500\n",
      "141/141 [==============================] - 53s 377ms/step - loss: 2.4879e-04 - accuracy: 1.0000 - val_loss: 0.0177 - val_accuracy: 0.9950\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 2.7802e-04 - accuracy: 0.9999\n",
      "Epoch 27: val_accuracy did not improve from 0.99500\n",
      "141/141 [==============================] - 54s 380ms/step - loss: 2.7802e-04 - accuracy: 0.9999 - val_loss: 0.0216 - val_accuracy: 0.9950\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0072 - accuracy: 0.9980\n",
      "Epoch 28: val_accuracy did not improve from 0.99500\n",
      "141/141 [==============================] - 53s 376ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.0518 - val_accuracy: 0.9840\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0204 - accuracy: 0.9940\n",
      "Epoch 29: val_accuracy did not improve from 0.99500\n",
      "141/141 [==============================] - 53s 379ms/step - loss: 0.0204 - accuracy: 0.9940 - val_loss: 0.0413 - val_accuracy: 0.9870\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0175 - accuracy: 0.9944\n",
      "Epoch 30: val_accuracy did not improve from 0.99500\n",
      "141/141 [==============================] - 53s 377ms/step - loss: 0.0175 - accuracy: 0.9944 - val_loss: 0.1174 - val_accuracy: 0.9640\n",
      "Epoch 30: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X0, Y0, validation_data = (X1, Y1), epochs=EPOCHS, batch_size=64, callbacks=callbacks_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ddeb6c3-5958-40ce-a2ee-a3700756f9fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict ACC: 0.9864333333333334\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(model_path)\n",
    "Yhat = crowd_label(best_model, train_X)\n",
    "print(f\"Predict ACC: {(Yhat == train_y).sum() / len(Yhat)}\")\n",
    "# np.save(Yhat_path, Yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827833c6-26e9-4151-a48d-27a067aaba65",
   "metadata": {},
   "source": [
    "# Model 4: EfficientNet-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac282a4-7160-4f97-9580-4057c1d5c1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"EfficientNet-1\"\n",
    "model_path = base_path + f\"{model_name}.keras\"\n",
    "Yhat_path = f\"./crowd labels/{model_name}_y.npy\"\n",
    "callbacks_list = [ ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                   EarlyStopping(monitor='val_accuracy', patience=10, verbose=2, mode='auto'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8c5b8b7c-e559-45f8-bc97-385baea3aa46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 0.2023 - accuracy: 0.9394\n",
      "Epoch 1: val_accuracy improved from -inf to 0.98400, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/EfficientNet-1.keras\n",
      "141/141 [==============================] - 67s 410ms/step - loss: 0.2023 - accuracy: 0.9394 - val_loss: 0.0548 - val_accuracy: 0.9840\n"
     ]
    }
   ],
   "source": [
    "# Model 4: EfficientNet-1\n",
    "feature_extractor = keras.applications.EfficientNetB0(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "output = final_model(inputs, feature_extractor, K) \n",
    "model = tf.keras.Model(inputs=inputs, outputs=output, name=model_name)\n",
    "\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "history = model.fit(X0, Y0, validation_data = (X1, Y1), epochs=1, batch_size=64, callbacks=callbacks_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a42512e5-ef47-4dfd-a949-7a02435d61bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(model_path)\n",
    "Yhat = crowd_label(best_model, train_X)\n",
    "np.save(Yhat_path, Yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "010e7cca-8e17-4b25-af96-0d80b8e2dd96",
   "metadata": {},
   "source": [
    "## Model 5: Xception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f44ba2d4-84db-4b10-83d7-3c8d327332ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Xception\"\n",
    "model_path = base_path + f\"{model_name}.keras\"\n",
    "Yhat_path = f\"./crowd labels/{model_name}_y.npy\"\n",
    "callbacks_list = [ ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                   EarlyStopping(monitor='val_accuracy', patience=10, verbose=2, mode='auto'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "98e589af-847b-410c-925c-8efe814fc876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/xception/xception_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "83689472/83683744 [==============================] - 120s 1us/step\n",
      "83697664/83683744 [==============================] - 120s 1us/step\n"
     ]
    }
   ],
   "source": [
    "# Model 5: Xception\n",
    "feature_extractor = keras.applications.Xception(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "output = final_model(inputs, feature_extractor, K) \n",
    "model = tf.keras.Model(inputs=inputs, outputs=output, name=model_name)\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82d3b65d-e197-4251-9370-2999cc46bf81",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1946 - accuracy: 0.9421\n",
      "Epoch 1: val_accuracy improved from -inf to 0.82600, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/Xception.keras\n",
      "141/141 [==============================] - 109s 725ms/step - loss: 0.1946 - accuracy: 0.9421 - val_loss: 1.0682 - val_accuracy: 0.8260\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0662 - accuracy: 0.9819\n",
      "Epoch 2: val_accuracy did not improve from 0.82600\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0662 - accuracy: 0.9819 - val_loss: 2.0840 - val_accuracy: 0.7650\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0510 - accuracy: 0.9870\n",
      "Epoch 3: val_accuracy improved from 0.82600 to 0.91600, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/Xception.keras\n",
      "141/141 [==============================] - 100s 709ms/step - loss: 0.0510 - accuracy: 0.9870 - val_loss: 0.2583 - val_accuracy: 0.9160\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0332 - accuracy: 0.9899\n",
      "Epoch 4: val_accuracy improved from 0.91600 to 0.98400, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/Xception.keras\n",
      "141/141 [==============================] - 101s 715ms/step - loss: 0.0332 - accuracy: 0.9899 - val_loss: 0.0538 - val_accuracy: 0.9840\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0359 - accuracy: 0.9901\n",
      "Epoch 5: val_accuracy did not improve from 0.98400\n",
      "141/141 [==============================] - 95s 674ms/step - loss: 0.0359 - accuracy: 0.9901 - val_loss: 0.1142 - val_accuracy: 0.9670\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0244 - accuracy: 0.9948\n",
      "Epoch 6: val_accuracy did not improve from 0.98400\n",
      "141/141 [==============================] - 95s 676ms/step - loss: 0.0244 - accuracy: 0.9948 - val_loss: 0.1558 - val_accuracy: 0.9620\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0385 - accuracy: 0.9888\n",
      "Epoch 7: val_accuracy did not improve from 0.98400\n",
      "141/141 [==============================] - 95s 677ms/step - loss: 0.0385 - accuracy: 0.9888 - val_loss: 0.1104 - val_accuracy: 0.9770\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0231 - accuracy: 0.9939\n",
      "Epoch 8: val_accuracy did not improve from 0.98400\n",
      "141/141 [==============================] - 95s 676ms/step - loss: 0.0231 - accuracy: 0.9939 - val_loss: 0.1056 - val_accuracy: 0.9730\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0184 - accuracy: 0.9951\n",
      "Epoch 9: val_accuracy did not improve from 0.98400\n",
      "141/141 [==============================] - 96s 681ms/step - loss: 0.0184 - accuracy: 0.9951 - val_loss: 0.1108 - val_accuracy: 0.9840\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0140 - accuracy: 0.9964\n",
      "Epoch 10: val_accuracy did not improve from 0.98400\n",
      "141/141 [==============================] - 95s 676ms/step - loss: 0.0140 - accuracy: 0.9964 - val_loss: 0.0783 - val_accuracy: 0.9800\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0165 - accuracy: 0.9956\n",
      "Epoch 11: val_accuracy improved from 0.98400 to 0.98500, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/Xception.keras\n",
      "141/141 [==============================] - 101s 713ms/step - loss: 0.0165 - accuracy: 0.9956 - val_loss: 0.0670 - val_accuracy: 0.9850\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0343 - accuracy: 0.9916\n",
      "Epoch 12: val_accuracy did not improve from 0.98500\n",
      "141/141 [==============================] - 95s 676ms/step - loss: 0.0343 - accuracy: 0.9916 - val_loss: 0.0709 - val_accuracy: 0.9810\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9927\n",
      "Epoch 13: val_accuracy did not improve from 0.98500\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0246 - accuracy: 0.9927 - val_loss: 0.1208 - val_accuracy: 0.9730\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9931\n",
      "Epoch 14: val_accuracy did not improve from 0.98500\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0235 - accuracy: 0.9931 - val_loss: 0.1826 - val_accuracy: 0.9660\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0187 - accuracy: 0.9944\n",
      "Epoch 15: val_accuracy improved from 0.98500 to 0.99200, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/Xception.keras\n",
      "141/141 [==============================] - 100s 713ms/step - loss: 0.0187 - accuracy: 0.9944 - val_loss: 0.0257 - val_accuracy: 0.9920\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9970\n",
      "Epoch 16: val_accuracy improved from 0.99200 to 0.99400, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/Xception.keras\n",
      "141/141 [==============================] - 106s 754ms/step - loss: 0.0094 - accuracy: 0.9970 - val_loss: 0.0189 - val_accuracy: 0.9940\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0055 - accuracy: 0.9984\n",
      "Epoch 17: val_accuracy did not improve from 0.99400\n",
      "141/141 [==============================] - 95s 674ms/step - loss: 0.0055 - accuracy: 0.9984 - val_loss: 0.0473 - val_accuracy: 0.9880\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0214 - accuracy: 0.9941\n",
      "Epoch 18: val_accuracy did not improve from 0.99400\n",
      "141/141 [==============================] - 95s 674ms/step - loss: 0.0214 - accuracy: 0.9941 - val_loss: 0.0739 - val_accuracy: 0.9790\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0080 - accuracy: 0.9976\n",
      "Epoch 19: val_accuracy did not improve from 0.99400\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.0287 - val_accuracy: 0.9890\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0033 - accuracy: 0.9989\n",
      "Epoch 20: val_accuracy did not improve from 0.99400\n",
      "141/141 [==============================] - 95s 674ms/step - loss: 0.0033 - accuracy: 0.9989 - val_loss: 0.0286 - val_accuracy: 0.9930\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0057 - accuracy: 0.9983\n",
      "Epoch 21: val_accuracy improved from 0.99400 to 0.99600, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/Xception.keras\n",
      "141/141 [==============================] - 100s 708ms/step - loss: 0.0057 - accuracy: 0.9983 - val_loss: 0.0213 - val_accuracy: 0.9960\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0135 - accuracy: 0.9970\n",
      "Epoch 22: val_accuracy did not improve from 0.99600\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0135 - accuracy: 0.9970 - val_loss: 0.0568 - val_accuracy: 0.9900\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0075 - accuracy: 0.9978\n",
      "Epoch 23: val_accuracy did not improve from 0.99600\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0075 - accuracy: 0.9978 - val_loss: 0.0630 - val_accuracy: 0.9850\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0217 - accuracy: 0.9941\n",
      "Epoch 24: val_accuracy did not improve from 0.99600\n",
      "141/141 [==============================] - 96s 679ms/step - loss: 0.0217 - accuracy: 0.9941 - val_loss: 0.0714 - val_accuracy: 0.9860\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0133 - accuracy: 0.9966\n",
      "Epoch 25: val_accuracy did not improve from 0.99600\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0133 - accuracy: 0.9966 - val_loss: 0.0652 - val_accuracy: 0.9870\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0091 - accuracy: 0.9973\n",
      "Epoch 26: val_accuracy did not improve from 0.99600\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0091 - accuracy: 0.9973 - val_loss: 0.0497 - val_accuracy: 0.9840\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0084 - accuracy: 0.9974\n",
      "Epoch 27: val_accuracy did not improve from 0.99600\n",
      "141/141 [==============================] - 95s 676ms/step - loss: 0.0084 - accuracy: 0.9974 - val_loss: 0.0300 - val_accuracy: 0.9920\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0104 - accuracy: 0.9969\n",
      "Epoch 28: val_accuracy did not improve from 0.99600\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0104 - accuracy: 0.9969 - val_loss: 0.0295 - val_accuracy: 0.9950\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0039 - accuracy: 0.9987\n",
      "Epoch 29: val_accuracy improved from 0.99600 to 0.99800, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/Xception.keras\n",
      "141/141 [==============================] - 100s 712ms/step - loss: 0.0039 - accuracy: 0.9987 - val_loss: 0.0085 - val_accuracy: 0.9980\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0060 - accuracy: 0.9986\n",
      "Epoch 30: val_accuracy did not improve from 0.99800\n",
      "141/141 [==============================] - 95s 676ms/step - loss: 0.0060 - accuracy: 0.9986 - val_loss: 0.5383 - val_accuracy: 0.9080\n",
      "Epoch 31/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0199 - accuracy: 0.9938\n",
      "Epoch 31: val_accuracy did not improve from 0.99800\n",
      "141/141 [==============================] - 95s 676ms/step - loss: 0.0199 - accuracy: 0.9938 - val_loss: 0.3812 - val_accuracy: 0.9440\n",
      "Epoch 32/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0238 - accuracy: 0.9951\n",
      "Epoch 32: val_accuracy did not improve from 0.99800\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0238 - accuracy: 0.9951 - val_loss: 0.0690 - val_accuracy: 0.9810\n",
      "Epoch 33/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9964\n",
      "Epoch 33: val_accuracy did not improve from 0.99800\n",
      "141/141 [==============================] - 95s 676ms/step - loss: 0.0090 - accuracy: 0.9964 - val_loss: 0.0489 - val_accuracy: 0.9900\n",
      "Epoch 34/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0090 - accuracy: 0.9979\n",
      "Epoch 34: val_accuracy did not improve from 0.99800\n",
      "141/141 [==============================] - 95s 676ms/step - loss: 0.0090 - accuracy: 0.9979 - val_loss: 0.1022 - val_accuracy: 0.9820\n",
      "Epoch 35/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0094 - accuracy: 0.9976\n",
      "Epoch 35: val_accuracy did not improve from 0.99800\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0094 - accuracy: 0.9976 - val_loss: 0.0271 - val_accuracy: 0.9940\n",
      "Epoch 36/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0040 - accuracy: 0.9988\n",
      "Epoch 36: val_accuracy did not improve from 0.99800\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0040 - accuracy: 0.9988 - val_loss: 0.0268 - val_accuracy: 0.9900\n",
      "Epoch 37/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0100 - accuracy: 0.9982\n",
      "Epoch 37: val_accuracy did not improve from 0.99800\n",
      "141/141 [==============================] - 95s 676ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.0226 - val_accuracy: 0.9930\n",
      "Epoch 38/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0027 - accuracy: 0.9991\n",
      "Epoch 38: val_accuracy did not improve from 0.99800\n",
      "141/141 [==============================] - 95s 676ms/step - loss: 0.0027 - accuracy: 0.9991 - val_loss: 0.0079 - val_accuracy: 0.9970\n",
      "Epoch 39/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0032 - accuracy: 0.9994\n",
      "Epoch 39: val_accuracy did not improve from 0.99800\n",
      "141/141 [==============================] - 95s 675ms/step - loss: 0.0032 - accuracy: 0.9994 - val_loss: 0.0055 - val_accuracy: 0.9970\n",
      "Epoch 39: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X0, Y0, validation_data = (X1, Y1), epochs=EPOCHS, batch_size=64, callbacks=callbacks_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b97801e6-95d5-48ea-93e7-4c19f4b344a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict ACC: 0.9896\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(model_path)\n",
    "Yhat = crowd_label(best_model, train_X)\n",
    "print(f\"Predict ACC: {(Yhat == train_y).sum() / len(Yhat)}\")\n",
    "# np.save(Yhat_path, Yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6b526-afb5-4ae2-85a8-eec96418e76c",
   "metadata": {},
   "source": [
    "# Model 6: Xception-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f23dcff-eff1-41ff-9fba-f758720c6351",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"Xception-1\"\n",
    "model_path = base_path + f\"{model_name}.keras\"\n",
    "Yhat_path = f\"./crowd labels/{model_name}_y.npy\"\n",
    "callbacks_list = [ ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                   EarlyStopping(monitor='val_accuracy', patience=10, verbose=2, mode='auto'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0cdf93d1-e59a-45f4-8c4c-49e30a628a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor = keras.applications.Xception(include_top=False, input_shape=(224, 224, 3), weights=\"imagenet\")\n",
    "output = final_model(inputs, feature_extractor, K)\n",
    "model = tf.keras.Model(inputs=inputs, outputs=output, name=model_name)\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3c0f45ed-04e1-4b6a-a51d-69ca85fbaebd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2219 - accuracy: 0.9361\n",
      "Epoch 1: val_accuracy improved from -inf to 0.98800, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/Xception-5.keras\n",
      "141/141 [==============================] - 107s 724ms/step - loss: 0.2219 - accuracy: 0.9361 - val_loss: 0.0565 - val_accuracy: 0.9880\n",
      "Epoch 2/5\n",
      " 34/141 [======>.......................] - ETA: 1:11 - loss: 0.0524 - accuracy: 0.9876"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_32404/2183264162.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1387\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[0;31m# No error, now safe to assign to logs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m    436\u001b[0m     \"\"\"\n\u001b[1;32m    437\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 438\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[0;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[1;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'end'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m       raise ValueError(\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[0;34m(self, mode, batch, logs)\u001b[0m\n\u001b[1;32m    316\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 318\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[0;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m       \u001b[0mhook\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m       \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1032\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1034\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1035\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[0;34m(self, batch, logs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m       \u001b[0;31m# Only block async when verbose = 1.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1106\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1107\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    561\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 563\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[0;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    913\u001b[0m   return pack_sequence_as(\n\u001b[0;32m--> 914\u001b[0;31m       \u001b[0mstructure\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    915\u001b[0m       expand_composites=expand_composites)\n\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/utils/tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m       \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m     \u001b[0;31m# Strings, ragged and sparse tensors don't have .item(). Return them as-is.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgeneric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1221\u001b[0m     \"\"\"\n\u001b[1;32m   1222\u001b[0m     \u001b[0;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1223\u001b[0;31m     \u001b[0mmaybe_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1224\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1187\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1188\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1189\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1190\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1191\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X0, Y0, validation_data = (X1, Y1), epochs=1, batch_size=64, callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "13626448-5700-4ac2-8a24-af457c09e934",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(model_path)\n",
    "Yhat = crowd_label(best_model, train_X)\n",
    "np.save(Yhat_path, Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62e7781f-f32f-452a-a294-4eaf7f3246dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict ACC: 0.9665166666666667\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predict ACC: {(Yhat == train_y).sum() / len(Yhat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99573e6f-7d49-42ab-97d4-2ca649c97dfc",
   "metadata": {},
   "source": [
    "## Model 7: VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "746eb100-42ad-4c3f-b2a1-5872ef985554",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"VGG16\"\n",
    "model_path = base_path + f\"{model_name}.keras\"\n",
    "Yhat_path = f\"./crowd labels/{model_name}_y.npy\"\n",
    "callbacks_list = [ ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                   EarlyStopping(monitor='val_accuracy', patience=10, verbose=2, mode='auto'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04d395f9-5c3b-4cfd-9fab-16c1f2a59ecc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "58892288/58889256 [==============================] - 494s 8us/step\n",
      "58900480/58889256 [==============================] - 494s 8us/step\n"
     ]
    }
   ],
   "source": [
    "# Model 7: VGG16\n",
    "feature_extractor = keras.applications.VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "output = final_model(inputs, feature_extractor, K) \n",
    "model = tf.keras.Model(inputs=inputs, outputs=output, name=model_name)\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e0168ecb-f1bc-455a-8eff-5c440bf0d828",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 3.4186 - accuracy: 0.4641\n",
      "Epoch 1: val_accuracy improved from -inf to 0.73400, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16.keras\n",
      "141/141 [==============================] - 68s 448ms/step - loss: 3.4186 - accuracy: 0.4641 - val_loss: 0.8340 - val_accuracy: 0.7340\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.4626 - accuracy: 0.8493\n",
      "Epoch 2: val_accuracy improved from 0.73400 to 0.88700, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16.keras\n",
      "141/141 [==============================] - 60s 423ms/step - loss: 0.4626 - accuracy: 0.8493 - val_loss: 0.3249 - val_accuracy: 0.8870\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2558 - accuracy: 0.9158\n",
      "Epoch 3: val_accuracy improved from 0.88700 to 0.92100, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16.keras\n",
      "141/141 [==============================] - 60s 426ms/step - loss: 0.2558 - accuracy: 0.9158 - val_loss: 0.1960 - val_accuracy: 0.9210\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1774 - accuracy: 0.9431\n",
      "Epoch 4: val_accuracy improved from 0.92100 to 0.94700, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16.keras\n",
      "141/141 [==============================] - 60s 426ms/step - loss: 0.1774 - accuracy: 0.9431 - val_loss: 0.1699 - val_accuracy: 0.9470\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1151 - accuracy: 0.9643\n",
      "Epoch 5: val_accuracy improved from 0.94700 to 0.97200, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16.keras\n",
      "141/141 [==============================] - 60s 426ms/step - loss: 0.1151 - accuracy: 0.9643 - val_loss: 0.1186 - val_accuracy: 0.9720\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0900 - accuracy: 0.9722\n",
      "Epoch 6: val_accuracy improved from 0.97200 to 0.97300, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16.keras\n",
      "141/141 [==============================] - 60s 425ms/step - loss: 0.0900 - accuracy: 0.9722 - val_loss: 0.0775 - val_accuracy: 0.9730\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0627 - accuracy: 0.9781\n",
      "Epoch 7: val_accuracy improved from 0.97300 to 0.97400, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16.keras\n",
      "141/141 [==============================] - 60s 424ms/step - loss: 0.0627 - accuracy: 0.9781 - val_loss: 0.0837 - val_accuracy: 0.9740\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0661 - accuracy: 0.9766\n",
      "Epoch 8: val_accuracy improved from 0.97400 to 0.97500, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16.keras\n",
      "141/141 [==============================] - 60s 427ms/step - loss: 0.0661 - accuracy: 0.9766 - val_loss: 0.0813 - val_accuracy: 0.9750\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0516 - accuracy: 0.9830\n",
      "Epoch 9: val_accuracy improved from 0.97500 to 0.97800, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16.keras\n",
      "141/141 [==============================] - 60s 423ms/step - loss: 0.0516 - accuracy: 0.9830 - val_loss: 0.0667 - val_accuracy: 0.9780\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0378 - accuracy: 0.9864\n",
      "Epoch 10: val_accuracy did not improve from 0.97800\n",
      "141/141 [==============================] - 56s 400ms/step - loss: 0.0378 - accuracy: 0.9864 - val_loss: 0.0967 - val_accuracy: 0.9770\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0540 - accuracy: 0.9831\n",
      "Epoch 11: val_accuracy did not improve from 0.97800\n",
      "141/141 [==============================] - 56s 400ms/step - loss: 0.0540 - accuracy: 0.9831 - val_loss: 0.0926 - val_accuracy: 0.9670\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9866\n",
      "Epoch 12: val_accuracy did not improve from 0.97800\n",
      "141/141 [==============================] - 56s 401ms/step - loss: 0.0414 - accuracy: 0.9866 - val_loss: 0.0459 - val_accuracy: 0.9760\n",
      "Epoch 13/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0193 - accuracy: 0.9931\n",
      "Epoch 13: val_accuracy did not improve from 0.97800\n",
      "141/141 [==============================] - 57s 403ms/step - loss: 0.0193 - accuracy: 0.9931 - val_loss: 0.0571 - val_accuracy: 0.9760\n",
      "Epoch 14/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0276 - accuracy: 0.9896\n",
      "Epoch 14: val_accuracy improved from 0.97800 to 0.97900, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16.keras\n",
      "141/141 [==============================] - 60s 425ms/step - loss: 0.0276 - accuracy: 0.9896 - val_loss: 0.0878 - val_accuracy: 0.9790\n",
      "Epoch 15/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0340 - accuracy: 0.9892\n",
      "Epoch 15: val_accuracy improved from 0.97900 to 0.98200, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16.keras\n",
      "141/141 [==============================] - 60s 424ms/step - loss: 0.0340 - accuracy: 0.9892 - val_loss: 0.0601 - val_accuracy: 0.9820\n",
      "Epoch 16/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0292 - accuracy: 0.9911\n",
      "Epoch 16: val_accuracy did not improve from 0.98200\n",
      "141/141 [==============================] - 56s 400ms/step - loss: 0.0292 - accuracy: 0.9911 - val_loss: 0.0853 - val_accuracy: 0.9780\n",
      "Epoch 17/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0369 - accuracy: 0.9887\n",
      "Epoch 17: val_accuracy did not improve from 0.98200\n",
      "141/141 [==============================] - 56s 400ms/step - loss: 0.0369 - accuracy: 0.9887 - val_loss: 0.0969 - val_accuracy: 0.9690\n",
      "Epoch 18/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0345 - accuracy: 0.9890\n",
      "Epoch 18: val_accuracy did not improve from 0.98200\n",
      "141/141 [==============================] - 57s 401ms/step - loss: 0.0345 - accuracy: 0.9890 - val_loss: 0.0722 - val_accuracy: 0.9770\n",
      "Epoch 19/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0170 - accuracy: 0.9944\n",
      "Epoch 19: val_accuracy did not improve from 0.98200\n",
      "141/141 [==============================] - 56s 400ms/step - loss: 0.0170 - accuracy: 0.9944 - val_loss: 0.0699 - val_accuracy: 0.9790\n",
      "Epoch 20/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0215 - accuracy: 0.9926\n",
      "Epoch 20: val_accuracy improved from 0.98200 to 0.99100, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16.keras\n",
      "141/141 [==============================] - 60s 426ms/step - loss: 0.0215 - accuracy: 0.9926 - val_loss: 0.0285 - val_accuracy: 0.9910\n",
      "Epoch 21/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0243 - accuracy: 0.9919\n",
      "Epoch 21: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 57s 404ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 0.0344 - val_accuracy: 0.9910\n",
      "Epoch 22/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0161 - accuracy: 0.9957\n",
      "Epoch 22: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 56s 400ms/step - loss: 0.0161 - accuracy: 0.9957 - val_loss: 0.0244 - val_accuracy: 0.9900\n",
      "Epoch 23/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0073 - accuracy: 0.9977\n",
      "Epoch 23: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 56s 400ms/step - loss: 0.0073 - accuracy: 0.9977 - val_loss: 0.0304 - val_accuracy: 0.9870\n",
      "Epoch 24/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0274 - accuracy: 0.9916\n",
      "Epoch 24: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 56s 400ms/step - loss: 0.0274 - accuracy: 0.9916 - val_loss: 0.0640 - val_accuracy: 0.9860\n",
      "Epoch 25/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0155 - accuracy: 0.9946\n",
      "Epoch 25: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 56s 400ms/step - loss: 0.0155 - accuracy: 0.9946 - val_loss: 0.0656 - val_accuracy: 0.9840\n",
      "Epoch 26/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0235 - accuracy: 0.9924\n",
      "Epoch 26: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 56s 401ms/step - loss: 0.0235 - accuracy: 0.9924 - val_loss: 0.0896 - val_accuracy: 0.9800\n",
      "Epoch 27/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0151 - accuracy: 0.9957\n",
      "Epoch 27: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 56s 400ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.0819 - val_accuracy: 0.9880\n",
      "Epoch 28/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0197 - accuracy: 0.9934\n",
      "Epoch 28: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 56s 400ms/step - loss: 0.0197 - accuracy: 0.9934 - val_loss: 0.0296 - val_accuracy: 0.9900\n",
      "Epoch 29/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0174 - accuracy: 0.9958\n",
      "Epoch 29: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 57s 401ms/step - loss: 0.0174 - accuracy: 0.9958 - val_loss: 0.0337 - val_accuracy: 0.9890\n",
      "Epoch 30/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0167 - accuracy: 0.9950\n",
      "Epoch 30: val_accuracy did not improve from 0.99100\n",
      "141/141 [==============================] - 57s 404ms/step - loss: 0.0167 - accuracy: 0.9950 - val_loss: 0.0610 - val_accuracy: 0.9850\n",
      "Epoch 30: early stopping\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X0, Y0, validation_data = (X1, Y1), epochs=EPOCHS, batch_size=64, callbacks=callbacks_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad197b61-e6a9-410a-a172-b54fc88ff7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(model_path)\n",
    "Yhat = crowd_label(best_model, train_X)\n",
    "np.save(Yhat_path, Yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4be57f-232e-4d9d-8a16-783cfba6bb47",
   "metadata": {},
   "source": [
    "## Model 8: VGG16-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d482fd20-2f7c-413e-bacb-ec55ddce5d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"VGG16-5\"\n",
    "model_path = base_path + f\"{model_name}.keras\"\n",
    "Yhat_path = f\"./crowd labels/{model_name}_y.npy\"\n",
    "callbacks_list = [ ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                   EarlyStopping(monitor='val_accuracy', patience=10, verbose=2, mode='auto'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ef6222f5-6e5a-493c-ab2d-6f3689c7b348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 8: VGG16-5\n",
    "feature_extractor = keras.applications.VGG16(include_top=False, weights=\"imagenet\", input_shape=(224, 224, 3))\n",
    "output = final_model(inputs, feature_extractor, K) \n",
    "model = tf.keras.Model(inputs=inputs, outputs=output, name=model_name)\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d9e2c7c-810a-4b4d-a801-e925f9f47939",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "141/141 [==============================] - ETA: 0s - loss: 5.7201 - accuracy: 0.3543\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67200, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16-5.keras\n",
      "141/141 [==============================] - 61s 426ms/step - loss: 5.7201 - accuracy: 0.3543 - val_loss: 0.9393 - val_accuracy: 0.6720\n",
      "Epoch 2/5\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.7061 - accuracy: 0.7636\n",
      "Epoch 2: val_accuracy improved from 0.67200 to 0.87500, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16-5.keras\n",
      "141/141 [==============================] - 60s 425ms/step - loss: 0.7061 - accuracy: 0.7636 - val_loss: 0.3811 - val_accuracy: 0.8750\n",
      "Epoch 3/5\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.3407 - accuracy: 0.8922\n",
      "Epoch 3: val_accuracy improved from 0.87500 to 0.88200, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16-5.keras\n",
      "141/141 [==============================] - 61s 431ms/step - loss: 0.3407 - accuracy: 0.8922 - val_loss: 0.3665 - val_accuracy: 0.8820\n",
      "Epoch 4/5\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2078 - accuracy: 0.9374\n",
      "Epoch 4: val_accuracy improved from 0.88200 to 0.94700, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16-5.keras\n",
      "141/141 [==============================] - 61s 430ms/step - loss: 0.2078 - accuracy: 0.9374 - val_loss: 0.1868 - val_accuracy: 0.9470\n",
      "Epoch 5/5\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.1344 - accuracy: 0.9576\n",
      "Epoch 5: val_accuracy improved from 0.94700 to 0.95600, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/VGG16-5.keras\n",
      "141/141 [==============================] - 60s 429ms/step - loss: 0.1344 - accuracy: 0.9576 - val_loss: 0.1646 - val_accuracy: 0.9560\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X0, Y0, validation_data = (X1, Y1), epochs=5, batch_size=64, callbacks=callbacks_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d3a5cf7-bb6e-45c0-ac82-57ca9ad4ddd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(model_path)\n",
    "Yhat = crowd_label(best_model, train_X)\n",
    "np.save(Yhat_path, Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80a82d0c-54c8-4491-b6a7-8a8123f32883",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict ACC: 0.9393833333333333\n"
     ]
    }
   ],
   "source": [
    "print(f\"Predict ACC: {(Yhat == train_y).sum() / len(Yhat)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b54a11-0c5a-4f4d-98aa-0485f60d3e2e",
   "metadata": {},
   "source": [
    "## Model 9: ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dbafc621-f773-49ad-a9e2-c976c2998c6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ResNet50\"\n",
    "model_path = base_path + f\"{model_name}.keras\"\n",
    "Yhat_path = f\"./crowd labels/{model_name}_y.npy\"\n",
    "callbacks_list = [ ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                   EarlyStopping(monitor='val_accuracy', patience=10, verbose=2, mode='auto'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "790667c1-4331-4a40-b39b-34d4714cb07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 9: ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "feature_extractor = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "output = final_model(inputs, feature_extractor, K) \n",
    "model = tf.keras.Model(inputs=inputs, outputs=output, name=model_name)\n",
    "callbacks_list = [ ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                   EarlyStopping(monitor='val_accuracy', patience=10, verbose=2, mode='auto'),]\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18ab2501-0fa9-427e-a022-0c4fa0622aa0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.2478 - accuracy: 0.9238\n",
      "Epoch 1: val_accuracy improved from -inf to 0.31500, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/ResNet50.keras\n",
      "141/141 [==============================] - 60s 366ms/step - loss: 0.2478 - accuracy: 0.9238 - val_loss: 10.4991 - val_accuracy: 0.3150\n",
      "Epoch 2/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0794 - accuracy: 0.9759\n",
      "Epoch 2: val_accuracy improved from 0.31500 to 0.93500, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/ResNet50.keras\n",
      "141/141 [==============================] - 50s 354ms/step - loss: 0.0794 - accuracy: 0.9759 - val_loss: 0.3238 - val_accuracy: 0.9350\n",
      "Epoch 3/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0444 - accuracy: 0.9871\n",
      "Epoch 3: val_accuracy improved from 0.93500 to 0.97000, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/ResNet50.keras\n",
      "141/141 [==============================] - 50s 356ms/step - loss: 0.0444 - accuracy: 0.9871 - val_loss: 0.1156 - val_accuracy: 0.9700\n",
      "Epoch 4/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0473 - accuracy: 0.9853\n",
      "Epoch 4: val_accuracy did not improve from 0.97000\n",
      "141/141 [==============================] - 44s 313ms/step - loss: 0.0473 - accuracy: 0.9853 - val_loss: 0.2370 - val_accuracy: 0.9500\n",
      "Epoch 5/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0371 - accuracy: 0.9882\n",
      "Epoch 5: val_accuracy improved from 0.97000 to 0.97400, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/ResNet50.keras\n",
      "141/141 [==============================] - 50s 353ms/step - loss: 0.0371 - accuracy: 0.9882 - val_loss: 0.1048 - val_accuracy: 0.9740\n",
      "Epoch 6/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0246 - accuracy: 0.9929\n",
      "Epoch 6: val_accuracy improved from 0.97400 to 0.97500, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/ResNet50.keras\n",
      "141/141 [==============================] - 50s 356ms/step - loss: 0.0246 - accuracy: 0.9929 - val_loss: 0.1111 - val_accuracy: 0.9750\n",
      "Epoch 7/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0414 - accuracy: 0.9882\n",
      "Epoch 7: val_accuracy did not improve from 0.97500\n",
      "141/141 [==============================] - 44s 313ms/step - loss: 0.0414 - accuracy: 0.9882 - val_loss: 0.1336 - val_accuracy: 0.9620\n",
      "Epoch 8/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0153 - accuracy: 0.9952\n",
      "Epoch 8: val_accuracy did not improve from 0.97500\n",
      "141/141 [==============================] - 44s 313ms/step - loss: 0.0153 - accuracy: 0.9952 - val_loss: 0.1018 - val_accuracy: 0.9750\n",
      "Epoch 9/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0194 - accuracy: 0.9943\n",
      "Epoch 9: val_accuracy improved from 0.97500 to 0.98700, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/ResNet50.keras\n",
      "141/141 [==============================] - 50s 353ms/step - loss: 0.0194 - accuracy: 0.9943 - val_loss: 0.0445 - val_accuracy: 0.9870\n",
      "Epoch 10/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0294 - accuracy: 0.9917\n",
      "Epoch 10: val_accuracy did not improve from 0.98700\n",
      "141/141 [==============================] - 44s 313ms/step - loss: 0.0294 - accuracy: 0.9917 - val_loss: 0.0796 - val_accuracy: 0.9820\n",
      "Epoch 11/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0112 - accuracy: 0.9961\n",
      "Epoch 11: val_accuracy did not improve from 0.98700\n",
      "141/141 [==============================] - 44s 312ms/step - loss: 0.0112 - accuracy: 0.9961 - val_loss: 0.0549 - val_accuracy: 0.9870\n",
      "Epoch 12/50\n",
      "141/141 [==============================] - ETA: 0s - loss: 0.0160 - accuracy: 0.9950\n",
      "Epoch 12: val_accuracy improved from 0.98700 to 0.98900, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/ResNet50.keras\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_29651/1186015626.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1433\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1436\u001b[0m         \u001b[0mtraining_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m    414\u001b[0m     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_logs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m       \u001b[0mcallback\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36mon_epoch_end\u001b[0;34m(self, epoch, logs)\u001b[0m\n\u001b[1;32m   1386\u001b[0m     \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1387\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'epoch'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1388\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1390\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_should_save_on_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/callbacks.py\u001b[0m in \u001b[0;36m_save_model\u001b[0;34m(self, epoch, batch, logs)\u001b[0m\n\u001b[1;32m   1441\u001b[0m                     filepath, overwrite=True, options=self._options)\n\u001b[1;32m   1442\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1444\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m   2382\u001b[0m     \"\"\"\n\u001b[1;32m   2383\u001b[0m     \u001b[0;31m# pylint: enable=line-too-long\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2384\u001b[0;31m     save.save_model(self, filepath, overwrite, include_optimizer, save_format,\n\u001b[0m\u001b[1;32m   2385\u001b[0m                     signatures, options, save_traces)\n\u001b[1;32m   2386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/saving/save.py\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, include_optimizer, save_format, signatures, options, save_traces)\u001b[0m\n\u001b[1;32m    145\u001b[0m           \u001b[0;34m'to the Tensorflow SavedModel format (by setting save_format=\"tf\") '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m           'or using `save_weights`.')\n\u001b[0;32m--> 147\u001b[0;31m     hdf5_format.save_model_to_hdf5(\n\u001b[0m\u001b[1;32m    148\u001b[0m         model, filepath, overwrite, include_optimizer)\n\u001b[1;32m    149\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_model_to_hdf5\u001b[0;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[1;32m    129\u001b[0m     elif (include_optimizer and model.optimizer and\n\u001b[1;32m    130\u001b[0m           not isinstance(model.optimizer, optimizer_v1.TFOptimizer)):\n\u001b[0;32m--> 131\u001b[0;31m       \u001b[0msave_optimizer_weights_to_hdf5_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/keras/saving/hdf5_format.py\u001b[0m in \u001b[0;36msave_optimizer_weights_to_hdf5_group\u001b[0;34m(hdf5_group, optimizer)\u001b[0m\n\u001b[1;32m    609\u001b[0m         \u001b[0mparam_dset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    610\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 611\u001b[0;31m         \u001b[0mparam_dset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    612\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mh5py/_objects.pyx\u001b[0m in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/myconda/lib/python3.9/site-packages/h5py/_hl/dataset.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, args, val)\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0mmspace\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mh5s\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfspace\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mselection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 982\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfspace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdxpl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dxpl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    983\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    984\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_direct\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msource_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdest_sel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "history = model.fit(X0, Y0, validation_data = (X1, Y1), epochs=EPOCHS, batch_size=64, callbacks=callbacks_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d80c91e8-1515-4558-9c26-42a25dd3b864",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = tf.keras.models.load_model(model_path)\n",
    "Yhat = crowd_label(best_model, train_X)\n",
    "np.save(Yhat_path, Yhat)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2727549-9811-46b8-8be7-1ac3bb5a0b70",
   "metadata": {},
   "source": [
    "# Model 10: ResNet50-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "178ae9b7-e485-45aa-ab06-2b199b0198b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"ResNet50-1\"\n",
    "model_path = base_path + f\"{model_name}.keras\"\n",
    "Yhat_path = f\"./crowd labels/{model_name}_y.npy\"\n",
    "callbacks_list = [ ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                   EarlyStopping(monitor='val_accuracy', patience=10, verbose=2, mode='auto'),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "12a28220-8b03-408c-9bb4-7fbeb430708d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 06:04:16.601468: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-26 06:04:17.728258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 15401 MB memory:  -> device: 0, name: Tesla P100-SXM2-16GB, pci bus id: 0000:1d:00.0, compute capability: 6.0\n"
     ]
    }
   ],
   "source": [
    "# Model 10: ResNet50-1\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "feature_extractor = ResNet50(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "output = final_model(inputs, feature_extractor, K) \n",
    "model = tf.keras.Model(inputs=inputs, outputs=output, name=model_name)\n",
    "callbacks_list = [ ModelCheckpoint(model_path, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max'),\n",
    "                   EarlyStopping(monitor='val_accuracy', patience=10, verbose=2, mode='auto'),]\n",
    "model.compile(optimizer=Adam(0.001), loss='categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64495a06-bd4a-45c5-9f89-c413c724df78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-26 06:06:36.010018: I tensorflow/stream_executor/cuda/cuda_dnn.cc:368] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - ETA: 0s - loss: 0.2508 - accuracy: 0.9244\n",
      "Epoch 1: val_accuracy improved from -inf to 0.86800, saving model to /mnt/Crowdsourcing/codes/mnist_experiment/crowd models/ResNet50-1.keras\n",
      "141/141 [==============================] - 59s 367ms/step - loss: 0.2508 - accuracy: 0.9244 - val_loss: 1.1418 - val_accuracy: 0.8680\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X0, Y0, validation_data = (X1, Y1), epochs=1, batch_size=64, callbacks=callbacks_list,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d17b186a-441e-47b0-8a8d-9e3fd4ae2b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predict ACC: 0.8552666666666666\n"
     ]
    }
   ],
   "source": [
    "best_model = tf.keras.models.load_model(model_path)\n",
    "Yhat = crowd_label(best_model, train_X)\n",
    "print(f\"Predict ACC: {(Yhat == train_y).sum() / len(Yhat)}\")\n",
    "# np.save(Yhat_path, Yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09f1f0d-b223-4db4-b451-6abf2ff59320",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myconda",
   "language": "python",
   "name": "myconda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
